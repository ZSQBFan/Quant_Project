# core/abstractions.py

from abc import ABC, abstractmethod
from typing import Any, Dict, List
import pandas as pd
import logging
from tqdm import tqdm  # <-- ã€ã€ã€æ–°å¢žå¯¼å…¥ã€‘ã€‘ã€‘

# ==============================================================================
#                 --- æ¡†æž¶æŽ¥å£å®šä¹‰ (Framework Interfaces) ---
# ==============================================================================


class BaseStandardizer(ABC):
    """ã€æŠ½è±¡åŸºç±»ã€‘: å› å­æ ‡å‡†åŒ–å™¨"""

    @abstractmethod
    def standardize(self, raw_signals_df: pd.DataFrame) -> pd.DataFrame:
        pass


class BaseFactorCombiner(ABC):
    """ã€æŠ½è±¡åŸºç±»ã€‘: å› å­åˆæˆå™¨"""

    def __init__(self, **kwargs):
        pass

    @abstractmethod
    def combine(self, standardized_df: pd.DataFrame) -> pd.Series:
        pass


class RollingCalculatorBase(ABC):
    """ã€æŠ½è±¡åŸºç±»ã€‘: æ»šåŠ¨è®¡ç®—å™¨"""

    def __init__(self,
                 factor_names: List[str],
                 rolling_window_days: int,
                 weight_update_frequency: str = 'MS',
                 **kwargs):
        self.factor_names = factor_names
        self.rolling_window_days = rolling_window_days
        self.weight_update_frequency = weight_update_frequency
        self.current_payload = None

    @abstractmethod
    def _calculate_payload_for_day(
            self, historical_data_window: pd.DataFrame) -> Any:
        pass

    @abstractmethod
    def _combine_factors_for_day(self, payload: Any,
                                 daily_factors: pd.DataFrame) -> pd.Series:
        pass

    # ã€ã€ã€ä¿®æ­£ã€‘ã€‘ã€‘: æ¢å¤äº†è¢«é—æ¼çš„æ ¸å¿ƒâ€œæ¨¡æ¿æ–¹æ³•â€ã€‚
    # è¿™ä¸ªæ–¹æ³•å®šä¹‰äº†æ‰€æœ‰æ»šåŠ¨ç­–ç•¥å…±äº«çš„ã€ç»Ÿä¸€çš„æ‰§è¡Œæµç¨‹ã€‚
    def calculate_composite_factor(self,
                                   all_data_merged: pd.DataFrame) -> pd.Series:
        """
        ã€ã€ã€æ¨¡æ¿æ–¹æ³•ã€‘ã€‘ã€‘: è¿™æ˜¯å¤–éƒ¨è°ƒç”¨çš„ä¸»å…¥å£ï¼Œæ‰§è¡Œå®Œæ•´çš„æ»šåŠ¨åˆæˆæµç¨‹ã€‚
        """
        logging.info(f"âš™ï¸ å¼€å§‹æ¯æ—¥æ»šåŠ¨åˆæˆ (ç­–ç•¥: {self.__class__.__name__})...")
        all_dates = all_data_merged.index.get_level_values(
            'date').unique().sort_values()
        composite_factor_parts = {}

        ideal_weight_update_dates = pd.date_range(start=all_dates.min(),
                                              end=all_dates.max(),
                                              freq=self.weight_update_frequency)
        weight_update_dates_idx = all_dates.searchsorted(ideal_weight_update_dates,
                                                     side='right') - 1
        weight_update_dates = set(
            all_dates[weight_update_dates_idx[weight_update_dates_idx >= 0]].date)
        logging.info(f"  > â„¹ï¸ å·²ç”Ÿæˆ {len(weight_update_dates)} ä¸ªæƒé‡æ›´æ–°æ—¥ã€‚")

        for current_date in tqdm(all_dates,
                                 desc=f"[{self.__class__.__name__}] æ¯æ—¥è®¡ç®—"):
            if current_date.date() in weight_update_dates:
                window_end_date = current_date
                window_start_date = window_end_date - pd.DateOffset(
                    days=self.rolling_window_days)
                
                # ã€ä¿®å¤ã€‘ç¡®ä¿çª—å£åŒ…å«ä¸¤ç«¯ï¼Œå¹¶ä¸”åªåœ¨æœ‰è¶³å¤ŸåŽ†å²æ•°æ®æ—¶è®¡ç®—
                historical_window_mask = (
                    (all_data_merged.index.get_level_values('date')
                     >= window_start_date) &
                    (all_data_merged.index.get_level_values('date')
                     <= window_end_date))  # æ”¹ä¸º <= åŒ…å«å½“å‰æ—¥æœŸ
                
                historical_data_window = all_data_merged.loc[
                    historical_window_mask]
                
                # ã€ä¿®å¤ã€‘æ£€æŸ¥çª—å£å†…æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
                min_days_required = max(30, self.rolling_window_days // 2)  # è‡³å°‘éœ€è¦30å¤©æˆ–çª—å£ä¸€åŠçš„æ•°æ®
                window_days = len(historical_data_window.index.get_level_values('date').unique())
                
                if not historical_data_window.empty and window_days >= min_days_required:
                    logging.debug(f"ðŸ” [æ»šåŠ¨çª—å£] {current_date.date()}: ä½¿ç”¨ {window_days} å¤©åŽ†å²æ•°æ®")
                    new_payload = self._calculate_payload_for_day(
                        historical_data_window)
                    if new_payload is not None:
                        self.current_payload = new_payload
                        logging.debug(
                            f"  >  {current_date.date()} æƒé‡æ›´æ–°å®Œæˆã€‚")
                else:
                    logging.debug(
                        f"  > {current_date.date()}: åŽ†å²çª—å£æ•°æ®ä¸è¶³"
                        f"(åªæœ‰ {window_days} å¤©ï¼Œéœ€è¦è‡³å°‘ {min_days_required} å¤©)ï¼Œè·³è¿‡æ›´æ–°ã€‚")
                    
                    # ã€ä¿®å¤ã€‘å¦‚æžœæ²¡æœ‰è½½è·ï¼Œä½¿ç”¨ä¸€ä¸ªç®€å•çš„ç­‰æƒç­–ç•¥ä½œä¸ºå›žé€€
                    if self.current_payload is None:
                        logging.debug(f"  > ä½¿ç”¨ç­‰æƒå›žé€€ç­–ç•¥ä½œä¸ºåˆå§‹è½½è·")
                        self.current_payload = {f: 1.0/len(self.factor_names) for f in self.factor_names}

            if self.current_payload is None:
                continue

            current_day_factors = all_data_merged.loc[current_date][
                self.factor_names]
            
            # ã€è°ƒè¯•ã€‘æ£€æŸ¥å½“å¤©çš„å› å­å€¼
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] æ—¥æœŸ {current_date.date()}")
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] è½½è·: {self.current_payload}")
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] å½“å¤©å› å­å€¼å½¢çŠ¶: {current_day_factors.shape}")
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] å½“å¤©å› å­å€¼ç±»åž‹: {type(current_day_factors)}")
            
            # ã€å…³é”®ã€‘æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
            if current_day_factors.empty:
                logging.error(f"âŒ [æ»šåŠ¨åˆæˆ] é”™è¯¯: å½“å¤©å› å­æ•°æ®ä¸ºç©ºï¼")
                continue
                
            # ã€å…³é”®ã€‘æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            if len(current_day_factors) == 0:
                logging.error(f"âŒ [æ»šåŠ¨åˆæˆ] é”™è¯¯: å½“å¤©å› å­æ•°æ®é•¿åº¦ä¸º0ï¼")
                continue
                
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] å½“å¤©å› å­å€¼åˆ—: {list(current_day_factors.columns)}")
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] å½“å¤©å› å­å€¼ç´¢å¼•: {current_day_factors.index[:5] if len(current_day_factors) > 0 else 'ç©º'}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰NaN
            nan_counts = current_day_factors.isna().sum()
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] NaNæ•°é‡: {nan_counts.to_dict()}")
            
            # æ£€æŸ¥æ•°æ®ç±»åž‹
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] æ•°æ®ç±»åž‹:\n{current_day_factors.dtypes}")
            
            # å¦‚æžœdescribe()æ²¡æœ‰è¾“å‡ºï¼Œæ‰‹åŠ¨è®¡ç®—ä¸€äº›ç»Ÿè®¡é‡
            if not current_day_factors.empty:
                logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] éžç©ºå€¼æ•°é‡: {current_day_factors.count().to_dict()}")
                logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] å‡å€¼:\n{current_day_factors.mean()}")
                logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] æ ‡å‡†å·®:\n{current_day_factors.std()}")
                logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] æœ€å°å€¼:\n{current_day_factors.min()}")
                logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] æœ€å¤§å€¼:\n{current_day_factors.max()}")
            
            # ã€å…³é”®è°ƒè¯•ã€‘æ£€æŸ¥å› å­å€¼æ˜¯å¦å…¨ä¸º0æˆ–NaN
            if (current_day_factors == 0).all().all():
                logging.warning(f"âš ï¸ [æ»šåŠ¨åˆæˆ] è­¦å‘Š: å½“å¤©æ‰€æœ‰å› å­å€¼éƒ½ä¸º0ï¼")
                
            if current_day_factors.isna().all().all():
                logging.error(f"âŒ [æ»šåŠ¨åˆæˆ] è‡´å‘½é”™è¯¯: å½“å¤©æ‰€æœ‰å› å­å€¼éƒ½æ˜¯NaNï¼")
                
            # æ‰“å°ä¸€äº›æ ·æœ¬çœ‹çœ‹
            sample_data = current_day_factors.head(10)
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] æ ·æœ¬æ•°æ®:\n{sample_data}")
            
            daily_composite_factor = self._combine_factors_for_day(
                self.current_payload, current_day_factors)
                
            # ã€è°ƒè¯•ã€‘æ£€æŸ¥åˆæˆåŽçš„å› å­å€¼
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] åˆæˆå› å­å€¼å½¢çŠ¶: {daily_composite_factor.shape}")
            logging.debug(f"ðŸ” [æ»šåŠ¨åˆæˆ] åˆæˆå› å­ç»Ÿè®¡:\n{daily_composite_factor.describe()}")
            
            # ã€å…³é”®ã€‘æ£€æŸ¥åˆæˆåŽæ˜¯å¦å…¨ä¸º0
            if (daily_composite_factor == 0).all():
                logging.warning(f"âš ï¸ [æ»šåŠ¨åˆæˆ] è­¦å‘Š: åˆæˆå› å­å…¨ä¸º0ï¼")
            
            if daily_composite_factor is not None:
                composite_factor_parts[current_date] = daily_composite_factor

            if daily_composite_factor is not None:
                composite_factor_parts[current_date] = daily_composite_factor

        if not composite_factor_parts:
            logging.error("âŒ æ»šåŠ¨åˆæˆæœªèƒ½è®¡ç®—å‡ºä»»ä½•ç»“æžœã€‚")
            return pd.Series(dtype=float, name="factor_value")

        final_composite_factor = pd.concat(composite_factor_parts)
        final_composite_factor.index.names = ['date', 'asset']
        logging.info("âœ… æ¯æ—¥æ»šåŠ¨åˆæˆå®Œæˆã€‚")
        return final_composite_factor


class AITrainerBase(ABC):
    """ã€æŠ½è±¡åŸºç±»ã€‘: AIæ¨¡åž‹è®­ç»ƒå™¨"""

    def __init__(self, target_return_period: int, model_params: Dict[str, Any],
                 **kwargs):
        self.target_return_period = target_return_period
        self.return_col = f'forward_return_{self.target_return_period}d'
        self.model_params = model_params

    @abstractmethod
    def train_model(self, historical_data_window: pd.DataFrame,
                    factor_names: List[str]) -> Any:
        pass
