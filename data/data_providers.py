# data_providers.py
import pandas as pd
import akshare as ak
import tushare as ts
import time
import random
from tqdm import tqdm
from .database_handler import DatabaseHandler


class BaseDataProvider:
    """
    ã€é‡æ„ã€‘æ•°æ®æä¾›è€…çš„åŸºç¡€æŠ½è±¡ç±»ã€‚
    """

    def __init__(self, **kwargs):
        self.retries = kwargs.get('retries', 2)
        self.delay = kwargs.get('delay', 3 + random.uniform(-1.0, 1.0))

    def fetch_data(self, symbol: str, start_date: str,
                   end_date: str) -> pd.DataFrame | None:
        raise NotImplementedError("æ¯ä¸ªæ•°æ®æä¾›è€…å­ç±»éƒ½å¿…é¡»å®ç° fetch_data æ–¹æ³•ã€‚")


class AkshareDataProvider(BaseDataProvider):
    """
    ä½¿ç”¨ Akshare ä½œä¸ºæ•°æ®æºçš„å…·ä½“å®ç°ã€‚
    """

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.adjust = kwargs.get('adjust', "hfq")

    def fetch_data(self, symbol: str, start_date: str,
                   end_date: str) -> pd.DataFrame | None:
        tqdm.write(
            f"  [Akshareå°è¯•] æ­£åœ¨è·å– {symbol} ä» {start_date} åˆ° {end_date} çš„æ•°æ®...")
        for attempt in range(self.retries):
            try:
                if symbol.startswith('sh') or symbol.startswith('sz'):
                    df_raw = ak.stock_zh_index_daily(symbol=symbol)
                else:
                    df_raw = ak.stock_zh_a_hist(
                        symbol=symbol,
                        start_date=start_date.replace('-', ''),
                        end_date=end_date.replace('-', ''),
                        adjust=self.adjust)

                if df_raw is None or df_raw.empty or 'æ—¥æœŸ' not in df_raw.columns:
                    tqdm.write(
                        f"  ğŸŸ¡ [Akshareè­¦å‘Š] åœ¨ {start_date} - {end_date} èŒƒå›´å†…æœªè¿”å› '{symbol}' çš„æœ‰æ•ˆæ•°æ®ã€‚"
                    )
                    return None

                ak_columns = [
                    'æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢', 'æŒ¯å¹…', 'æ¶¨è·Œå¹…',
                    'æ¶¨è·Œé¢', 'æ¢æ‰‹ç‡'
                ]
                db_columns = [
                    'date', 'open', 'close', 'high', 'low', 'volume',
                    'turnover', 'amplitude', 'pct_change', 'price_change',
                    'turnover_rate'
                ]
                df_raw.rename(columns=dict(zip(ak_columns, db_columns)),
                              inplace=True)

                for col in db_columns:
                    if col not in df_raw.columns:
                        df_raw[col] = None

                df = df_raw[db_columns].copy()
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)

                numeric_cols = [
                    'open', 'close', 'high', 'low', 'turnover', 'amplitude',
                    'pct_change', 'price_change', 'turnover_rate'
                ]
                for col in numeric_cols:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                df['volume'] = pd.to_numeric(
                    df['volume'], errors='coerce').fillna(0).astype(int)

                df_final = df.loc[start_date:end_date]
                if not df_final.empty:
                    tqdm.write(
                        f"  âœ… [AkshareæˆåŠŸ] æˆåŠŸè·å– {symbol} çš„ {len(df_final)} æ¡æ•°æ®ã€‚"
                    )
                    return df_final
                else:
                    return None

            except Exception as e:
                tqdm.write(
                    f"  âŒ [Akshareé”™è¯¯] è·å– {symbol} æ•°æ®æ—¶å‡ºé”™ (å°è¯• {attempt + 1}/{self.retries}): {e}"
                )
                if attempt < self.retries - 1:
                    tqdm.write(f"    å°†åœ¨ {self.delay} ç§’åé‡è¯•...")
                    time.sleep(self.delay + random.uniform(0, 1))
                else:
                    tqdm.write(
                        f"  âŒ [Akshareå¤±è´¥] å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒä½¿ç”¨ Akshare è·å–è¯¥æ•°æ®ã€‚")
                    return None
        return None


class TushareDataProvider(BaseDataProvider):
    """
    ä½¿ç”¨ Tushare ä½œä¸ºæ•°æ®æºçš„å…·ä½“å®ç°ã€‚
    """

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.token = kwargs.get('token')
        if not self.token:
            raise ValueError("TushareDataProvider éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„ 'token' å‚æ•°ã€‚")
        self.pro = ts.pro_api(self.token)
        self.adjust = kwargs.get('adjust', "hfq")

    def _convert_symbol_to_ts_code(self, symbol):
        if symbol.startswith('sh') or symbol.startswith('sz'):
            return f"{symbol.replace('sh', '').replace('sz', '')}.SH" if symbol.startswith(
                'sh') else f"{symbol.replace('sh', '').replace('sz', '')}.SZ"
        return f"{symbol}.SH" if symbol.startswith('6') else f"{symbol}.SZ"

    def fetch_data(self, symbol: str, start_date: str,
                   end_date: str) -> pd.DataFrame | None:
        tqdm.write(
            f"  [Tushareå°è¯•] æ­£åœ¨è·å– {symbol} ä» {start_date} åˆ° {end_date} çš„æ•°æ®...")
        ts_code = self._convert_symbol_to_ts_code(symbol)

        for attempt in range(self.retries):
            try:
                df_raw = self.pro.daily(ts_code=ts_code,
                                        start_date=start_date.replace('-', ''),
                                        end_date=end_date.replace('-', ''))

                if df_raw is None or df_raw.empty:
                    tqdm.write(
                        f"  ğŸŸ¡ [Tushareè­¦å‘Š] åœ¨ {start_date} - {end_date} èŒƒå›´å†…æœªè¿”å› '{symbol}' çš„æœ‰æ•ˆæ•°æ®ã€‚"
                    )
                    return None

                adj_factor = self.pro.adj_factor(
                    ts_code=ts_code,
                    start_date=start_date.replace('-', ''),
                    end_date=end_date.replace('-', ''))

                if not adj_factor.empty:
                    df_raw = pd.merge(df_raw,
                                      adj_factor[['trade_date', 'adj_factor']],
                                      on='trade_date',
                                      how='left')
                    df_raw['adj_factor'] = df_raw['adj_factor'].ffill()

                    for col in ['open', 'high', 'low', 'close']:
                        df_raw[col] = df_raw[col] * df_raw['adj_factor']

                ts_columns = [
                    'trade_date', 'open', 'close', 'high', 'low', 'vol',
                    'amount', 'pct_chg', 'change'
                ]
                db_columns = [
                    'date', 'open', 'close', 'high', 'low', 'volume',
                    'turnover', 'pct_change', 'price_change'
                ]
                df_raw.rename(columns=dict(zip(ts_columns, db_columns)),
                              inplace=True)

                df_raw['volume'] = pd.to_numeric(
                    df_raw['volume'],
                    errors='coerce').fillna(0).astype(int) * 100
                df_raw['turnover'] = pd.to_numeric(
                    df_raw['turnover'],
                    errors='coerce').fillna(0).astype(float) * 1000

                full_db_columns = [
                    'date', 'open', 'close', 'high', 'low', 'volume',
                    'turnover', 'amplitude', 'pct_change', 'price_change',
                    'turnover_rate'
                ]
                for col in full_db_columns:
                    if col not in df_raw.columns:
                        df_raw[col] = None

                df = df_raw[full_db_columns].copy()
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
                df.sort_index(ascending=True, inplace=True)

                tqdm.write(f"  âœ… [TushareæˆåŠŸ] æˆåŠŸè·å– {symbol} çš„ {len(df)} æ¡æ•°æ®ã€‚")
                return df

            except Exception as e:
                tqdm.write(
                    f"  âŒ [Tushareé”™è¯¯] è·å– {symbol} æ•°æ®æ—¶å‡ºé”™ (å°è¯• {attempt + 1}/{self.retries}): {e}"
                )
                if attempt < self.retries - 1:
                    tqdm.write(f"    å°†åœ¨ {self.delay} ç§’åé‡è¯•...")
                    time.sleep(self.delay + random.uniform(0, 1))
                else:
                    tqdm.write(
                        f"  âŒ [Tushareå¤±è´¥] å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒä½¿ç”¨ Tushare è·å–è¯¥æ•°æ®ã€‚")
                    return None
        return None


class SQLiteDataProvider(BaseDataProvider):
    """
    ä½¿ç”¨å¦ä¸€ä¸ªSQLiteæ•°æ®åº“ä½œä¸ºæ•°æ®æºçš„å…·ä½“å®ç°ã€‚
    å®ƒä¼šè¿æ¥åˆ°æŒ‡å®šçš„æºæ•°æ®åº“æ–‡ä»¶ï¼ŒæŸ¥è¯¢æ•°æ®ï¼Œç„¶åè¿”å›ç»™ DataProviderManagerï¼Œ
    åè€…ä¼šå°†å…¶å­˜å…¥å›æµ‹ä¸“ç”¨çš„æ•°æ®åº“ä¸­ã€‚
    """

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.source_db_path = kwargs.get('db_path')
        if not self.source_db_path:
            raise ValueError("SQLiteDataProvider éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„ 'db_path' å‚æ•°ã€‚")

        self.source_db_handler = DatabaseHandler(db_path=self.source_db_path)
        self.table_name = kwargs.get('table_name', 'stock_daily_prices')

        default_mapping = {
            'ticker': 'code',
            '_date': 'date',
            '_open': 'open',
            '_high': 'high',
            '_low': 'low',
            '_close': 'close',
            '_volume': 'volume',
            '_value': 'turnover',
            '_return': 'pct_change'
        }
        self.column_mapping = kwargs.get('column_mapping', default_mapping)

        tqdm.write(
            f"  [SQLiteProvideråˆå§‹åŒ–] å·²è¿æ¥åˆ°æºæ•°æ®åº“: {self.source_db_path}, è¡¨: {self.table_name}"
        )

    def fetch_data(self, symbol: str, start_date: str,
                   end_date: str) -> pd.DataFrame | None:
        tqdm.write(
            f"  [SQLiteé€‚é…å™¨] æ­£åœ¨ä»è¡¨'{self.table_name}'è·å– {symbol} ({start_date} to {end_date}) çš„æ•°æ®..."
        )
        try:
            # 1. ã€æŸ¥è¯¢ä¿®æ­£ã€‘
            int_start_date = int(start_date.replace('-', ''))
            int_end_date = int(end_date.replace('-', ''))
            try:
                int_symbol = int(symbol)
            except ValueError:
                tqdm.write(f"  ğŸŸ¡ [SQLiteè­¦å‘Š] è‚¡ç¥¨ä»£ç  '{symbol}' æ— æ³•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå·²è·³è¿‡ã€‚")
                return None

            query = f"SELECT * FROM {self.table_name} WHERE ticker = ? AND _date BETWEEN ? AND ?"
            params = (int_symbol, int_start_date, int_end_date)
            df_raw = self.source_db_handler.query_data(query, params=params)

            if df_raw is None or df_raw.empty:
                tqdm.write(f"  ğŸŸ¡ [SQLiteè­¦å‘Š] åœ¨æºæ•°æ®åº“ä¸­æœªæ‰¾åˆ° '{symbol}' çš„æœ‰æ•ˆæ•°æ®ã€‚")
                return None

            # 2. ã€æ•°æ®è½¬æ¢ã€‘
            tqdm.write(f"  [SQLiteé€‚é…å™¨] å·²è·å– {len(df_raw)} æ¡åŸå§‹æ•°æ®ï¼Œæ­£åœ¨è¿›è¡Œæ ¼å¼è½¬æ¢...")
            df_transformed = pd.DataFrame()
            df_transformed['date'] = pd.to_datetime(
                df_raw[self.column_mapping.get('date', '_date')],
                format='%Y%m%d')

            target_to_source_map = {
                v: k
                for k, v in self.column_mapping.items()
            }
            numeric_cols = [
                'open', 'high', 'low', 'close', 'turnover', 'pct_change'
            ]

            for col in numeric_cols:
                source_col = target_to_source_map.get(col)
                if source_col and source_col in df_raw.columns:
                    df_transformed[col] = pd.to_numeric(df_raw[source_col],
                                                        errors='coerce')

            vol_source_col = target_to_source_map.get('volume')
            if vol_source_col and vol_source_col in df_raw.columns:
                df_transformed['volume'] = pd.to_numeric(
                    df_raw[vol_source_col],
                    errors='coerce').fillna(0).astype('int64')

            # =================================================================
            # ã€ã€ã€2.5 æ–°å¢ - æ•°æ®æ¸…æ´—ã€‘ã€‘ã€‘
            # åœ¨ä¿å­˜åˆ°æ•°æ®åº“å‰ï¼Œç§»é™¤ä»»ä½•åŒ…å«æ— æ•ˆæ•°æ®çš„è¡Œ
            # =================================================================
            tqdm.write(f"  [æ•°æ®æ¸…æ´—] æ¸…æ´—å‰å…± {len(df_transformed)} æ¡æ•°æ®ã€‚")

            # å®šä¹‰æ ¸å¿ƒåˆ—ï¼Œè¿™äº›åˆ—åœ¨å›æµ‹æ•°æ®åº“ä¸­æ˜¯ NOT NULL çš„
            critical_cols = ['open', 'high', 'low', 'close', 'volume']

            # æ­¥éª¤ A: ä¸¢å¼ƒä»»ä½•æ ¸å¿ƒåˆ—æ˜¯ NaN (ç©ºå€¼) çš„è¡Œ
            df_transformed.dropna(subset=critical_cols, inplace=True)

            # æ­¥éª¤ B: ä¸¢å¼ƒä»·æ ¼ <= 0 æˆ–æˆäº¤é‡ < 0 çš„è¡Œ (æˆäº¤é‡ä¸º0æœ‰æ—¶æ˜¯æ­£å¸¸åœç‰Œï¼Œä½†ä¸ºè´Ÿä¸€å®šæ˜¯åæ•°æ®)
            # ä¸ºä¸¥æ ¼èµ·è§ï¼Œæˆ‘ä»¬ç§»é™¤æ‰€æœ‰ä»·æ ¼ä¸º0æˆ–è´Ÿæ•°çš„æ•°æ®
            price_cols = ['open', 'high', 'low', 'close']
            for col in price_cols:
                df_transformed = df_transformed[df_transformed[col] > 0]

            df_transformed = df_transformed[df_transformed['volume'] >= 0]

            tqdm.write(f"  [æ•°æ®æ¸…æ´—] æ¸…æ´—åå‰©ä½™ {len(df_transformed)} æ¡æœ‰æ•ˆæ•°æ®ã€‚")

            # å¦‚æœæ¸…æ´—åæ•°æ®ä¸ºç©ºï¼Œåˆ™ç›´æ¥è¿”å›
            if df_transformed.empty:
                tqdm.write(f"  ğŸŸ¡ [SQLiteè­¦å‘Š] æ¸…æ´—åï¼Œ'{symbol}' æ— å‰©ä½™æœ‰æ•ˆæ•°æ®ã€‚")
                return None
            # =================================================================
            # ã€æ•°æ®æ¸…æ´—ç»“æŸã€‘
            # =================================================================

            # 3. ã€æ ¼å¼ç»Ÿä¸€ã€‘
            final_columns = [
                'open', 'high', 'low', 'close', 'volume', 'turnover',
                'amplitude', 'pct_change', 'price_change', 'turnover_rate'
            ]
            for col in final_columns:
                if col not in df_transformed.columns:
                    df_transformed[col] = None

            df_transformed.set_index('date', inplace=True)

            tqdm.write(
                f"  âœ… [SQLiteæˆåŠŸ] æˆåŠŸè½¬æ¢å¹¶æ¸…æ´— {symbol} çš„ {len(df_transformed)} æ¡æ•°æ®ã€‚"
            )
            return df_transformed[final_columns]

        except Exception as e:
            tqdm.write(f"  âŒ [SQLiteé”™è¯¯] å¤„ç†æºæ•°æ®åº“æ•°æ®æ—¶å‡ºé”™: {e}")
            return None

    def __del__(self):
        if hasattr(self, 'source_db_handler'):
            self.source_db_handler.close_connection()
