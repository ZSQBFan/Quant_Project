# main_analyzer.py (å·²é‡æ„ - ä¿®æ­£å¤šè¿›ç¨‹è°ƒç”¨)

import os
import logging
import pandas as pd
from tqdm import tqdm
import sys

# ==============================================================================
# 1. ç­–ç•¥åˆ†æâ€œæ§åˆ¶é¢æ¿â€ (Strategy Analysis "Control Panel")
# ==============================================================================
#
#   æ¬¢è¿ä½¿ç”¨ï¼
#   æ‚¨å‡ ä¹æ‰€æœ‰çš„ã€é«˜é¢‘ã€‘è‡ªå®šä¹‰é…ç½®éƒ½å¯ä»¥åœ¨è¿™ä¸ªç‰ˆå—å®Œæˆã€‚
#   (å¯¹äºã€ä½é¢‘ã€‘çš„ç­–ç•¥å®šä¹‰ï¼Œè¯·è½¬åˆ° `strategy_configs.py` æ–‡ä»¶)
#
# ==============================================================================

# --- 1a. æ ¸å¿ƒç­–ç•¥é€‰æ‹© (Core Strategy Selection) ---
#
#   è¿™æ˜¯ã€æœ€é‡è¦ã€‘çš„ç­–ç•¥é€‰æ‹©ç‚¹ã€‚æ‰€æœ‰å¤æ‚çš„é…ç½® (æ»šåŠ¨å‘¨æœŸã€å›ºå®šæƒé‡ç­‰)
#   éƒ½å·²å°è£…åœ¨ `strategy_configs.py` æ–‡ä»¶ä¸­ã€‚
#
from strategy_configs import STRATEGY_REGISTRY

# ã€ã€è¯·åœ¨è¿™é‡Œé€‰æ‹©æ‚¨çš„ç­–ç•¥åç§° (ä» strategy_configs.py å¤åˆ¶)ã€‘ã€‘
# STRATEGY_NAME = "RollingICIR"
# STRATEGY_NAME = "RollingRegression"
# STRATEGY_NAME = "FixedWeights"
# STRATEGY_NAME = "EqualWeights"
# STRATEGY_NAME = "DynamicSignificance"
STRATEGY_NAME = "AI_Periodic_Retrain"

# --- (è‡ªåŠ¨åŠ è½½é…ç½®) ---
if STRATEGY_NAME not in STRATEGY_REGISTRY:
    # (è¿™ä¸ªæ—¥å¿—ä¼šåœ¨ setup_logging ä¹‹å‰ï¼Œå¯èƒ½æ— æ³•è¢«æ•è·ï¼Œä½† raise ä¼šç»ˆæ­¢ç¨‹åº)
    raise ValueError(f"ç­–ç•¥ '{STRATEGY_NAME}' æœªåœ¨ strategy_configs.py ä¸­æ³¨å†Œã€‚")
# è‡ªåŠ¨åŠ è½½æ‰€é€‰ç­–ç•¥çš„å®Œæ•´é…ç½®å¯¹è±¡
STRATEGY_CONFIG = STRATEGY_REGISTRY[STRATEGY_NAME]

# --- 1b. å› å­é€‰æ‹© (Factors to Analyze) ---
#
#   ã€ã€é‡è¦é…ç½®ã€‘ã€‘
#   æ‚¨å¸Œæœ›åœ¨æœ¬æ¬¡åˆ†æä¸­è¿è¡Œå“ªäº›ã€åŸºç¡€å› å­ (Type 1)ã€‘ï¼Ÿ
#
FACTORS_TO_ANALYZE = [
    # ('RSI', {
    #     'rsi_period': 22
    # }),
    # ('BollingerBands', {
    #     'period': 30
    # }),
    # ('ADXDMI', {
    #     'period': 14,
    #     'trend_threshold': 22
    # }),
    # ('Momentum', {
    #     'period': 20
    # }),
    # ('Reversal20D', {
    #     'period': 40,
    #     'decay': 20
    # }),
]

# --- 1c. å¤åˆå› å­é€‰æ‹© (Complex Factors) ---
#
#   ã€ã€é«˜çº§é…ç½®ã€‘ã€‘
#   æ‚¨å¸Œæœ›åœ¨ "Type 1" åŸºç¡€å› å­è®¡ç®—ã€ä¹‹åã€‘è¿è¡Œå“ªäº› "Type 2" å¤åˆå› å­ï¼Ÿ
#
from factor_analysis.factors_complex import COMPLEX_FACTOR_REGISTRY

COMPLEX_FACTORS_TO_RUN = [
    "IndNeu_Momentum",
    "IndNeu_Reversal20D",
    "IndNeu_VolumeCV",
    # "IndNeu_ADXDMI",
    # "MktNeu_RSI", # ç¤ºä¾‹: å¦‚æœæ‚¨åœ¨ `factors_complex.py` ä¸­å®šä¹‰äº†å®ƒ
]

# --- 1d. æˆªé¢æ•°æ®é…ç½® (Cross-Sectional Data) ---
#
#   ã€ã€é«˜çº§é…ç½®ã€‘ã€‘
#   æ‚¨æ˜¯å¦éœ€è¦åŠ è½½ã€é¢å¤–ã€‘çš„æˆªé¢æ•°æ® (ä¾‹å¦‚ è¡Œä¸šã€å¸‚å€¼)ï¼Ÿ
#
LOAD_INDUSTRY_DATA = True
# (å¦‚æœä¸éœ€è¦è¡Œä¸šæ•°æ®ï¼Œè¯·æ”¹ä¸º False)

# --- 1e. æ ‡å‡†åŒ–å™¨ (Standardizer) ---
#
#   ã€ã€é‡è¦é…ç½®ã€‘ã€‘
#   æ‚¨å¸Œæœ›å¦‚ä½•å¯¹å› å­å€¼è¿›è¡Œã€æˆªé¢æ ‡å‡†åŒ–ã€‘ï¼Ÿ
#
from strategies.standardizers import (CrossSectionalZScoreStandardizer,
                                      NoStandardizer,
                                      CrossSectionalQuantileStandardizer)
# ã€ã€è¯·åœ¨è¿™é‡Œä¸‰é€‰ä¸€ã€‘ã€‘
STANDARDIZER_CLASS = CrossSectionalZScoreStandardizer
# STANDARDIZER_CLASS = CrossSectionalQuantileStandardizer
# STANDARDIZER_CLASS = NoStandardizer

# ==============================================================================
# 2. åŸºç¡€å›æµ‹ä¸è·¯å¾„é…ç½® (Basic Backtest & Path Settings)
# ==============================================================================
#
# ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘æ•°æ®ä¸‹è½½ä¸å†™å…¥å¼€å…³ï¼š
#
#   å½“æ‚¨åªæ˜¯ä¿®æ”¹å› å­è®¡ç®— (factors.py) æˆ–åˆæˆé€»è¾‘ (factor_combiner.py)ï¼Œ
#   è€Œè‚¡ç¥¨æ± å’Œæ—¶é—´èŒƒå›´ä¸å˜æ—¶ï¼Œè¯·å°†æ­¤é¡¹è®¾ä¸º Trueã€‚
#   è¿™å°†è·³è¿‡è€—æ—¶çš„æ•°æ®æ£€æŸ¥å’Œä¸‹è½½æµç¨‹ï¼Œç›´æ¥ä½¿ç”¨æ•°æ®åº“ä¸­çš„ç°æœ‰æ•°æ®ã€‚
#
SKIP_DATA_PREPARATION = True
# SKIP_DATA_PREPARATION = False  # (æ­£å¸¸è¿è¡Œæ—¶è®¾ä¸º False)
#
# ==============================================================================

# --- 2a. å›æµ‹æ—¶é—´ä¸æ”¶ç›Šå‘¨æœŸ ---
START_DATE = '2018-01-01'
END_DATE = '2020-12-31'
FORWARD_RETURN_PERIODS = [1, 5, 10, 30, 60]  # å¿…é¡»åŒ…å« 1d ä¸­é…ç½®çš„æ‰€æœ‰å‘¨æœŸ

# --- 2b. åŸºå‡†ä¸è‚¡ç¥¨æ±  ---
BENCHMARK = '600519'  # ç”¨äºæŠ¥å‘Šå¯¹æ¯”
from universe_config import UNIVERSE  # å¯¼å…¥æ‚¨çš„è‚¡ç¥¨æ± 

# ã€ã€ã€æ–°å¢ã€‘ã€‘ã€‘: Type 1 å› å­è®¡ç®—ã€è¿›ç¨‹æ•°ã€‘
# (è¿™åœ¨ factor_calculator.py ä¸­è¢«ç”¨ä½œ max_workers)
FACTOR_CALC_PROCESSES = 16  # (æ ¹æ®æ‚¨çš„ CPU æ ¸å¿ƒæ•°è°ƒæ•´ï¼Œä¾‹å¦‚ 8, 16)

# --- 2c. è·¯å¾„é…ç½® ---
LOG_DIR = "logs"
OUTPUT_DIR = "factor_reports"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

BACKTEST_DB_PATH = './database/quant_data.db'

# --- 2d. æ•°æ®æºé…ç½® ---
from data.data_providers import SQLiteDataProvider

DATA_PROVIDERS_CONFIG = [
    (SQLiteDataProvider, {
        'db_path': './database/JY_database/sqlite/JY_database.sqlite',
        'table_name': 'JY_t_price_daily'
    }),
]

# ==============================================================================
#
#                     --- æ ¸å¿ƒç¨‹åºå¼€å§‹ (Core Logic Starts) ---
#                     --- (!!!) é€šå¸¸ä½ ä¸éœ€è¦ä¿®æ”¹ä»¥ä¸‹å†…å®¹ (!!!) ---
#
# ==============================================================================

# å¯¼å…¥æ‰€æœ‰å¿…éœ€çš„åˆ†ææ¨¡å—
from data.data_manager import DataProviderManager
from factor_analysis.factor_calculator import FactorCalculator
from factor_analysis.factor_report import FactorReport
from logger.logger_config import setup_logging

if __name__ == '__main__':

    # =====================
    # 0. åˆå§‹åŒ–ä¸é…ç½®æ ¡éªŒ
    # =====================
    # (setup_logging å¿…é¡»åœ¨æœ€å¼€å§‹è°ƒç”¨)
    setup_logging(log_dir=LOG_DIR, log_prefix='factor_analysis')
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 0: åˆå§‹åŒ–ä¸é…ç½®æ ¡éªŒ ---\n{'='*60}")
    logging.info("ğŸ å› å­åˆ†æç¨‹åºå¯åŠ¨...")

    # å®ä¾‹åŒ–æ ‡å‡†åŒ–å™¨
    STANDARDIZER = STANDARDIZER_CLASS()
    logging.info(f"âœ… æ ‡å‡†åŒ–å™¨å·²åŠ è½½: {STANDARDIZER.__class__.__name__}")
    logging.info(f"âš™ï¸ æ­£åœ¨åŠ è½½ç­–ç•¥: {STRATEGY_NAME}")
    logging.info("âœ… ç­–ç•¥é…ç½®åŠ è½½å®Œæ¯•ã€‚")

    # =====================
    # 1. åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨å¹¶å‡†å¤‡æ•°æ®
    # =====================
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 1: å‡†å¤‡æ•°æ® ---\n{'='*60}")
    logging.info("âš™ï¸ æ­£åœ¨åˆå§‹åŒ– DataProviderManager...")
    data_manager = DataProviderManager(provider_configs=DATA_PROVIDERS_CONFIG,
                                       symbols=UNIVERSE,
                                       start_date=START_DATE,
                                       end_date=END_DATE,
                                       db_path=BACKTEST_DB_PATH,
                                       num_checker_threads=16,
                                       num_downloader_threads=16,
                                       batch_size=200)

    # å°†åŸºå‡†æ·»åŠ åˆ°ä¸‹è½½åˆ—è¡¨
    if BENCHMARK not in data_manager.symbols:
        data_manager.symbols.append(BENCHMARK)
        logging.info(f"  > å·²å°†åŸºå‡† {BENCHMARK} æ·»åŠ åˆ°æ•°æ®ç®¡ç†å™¨ä»»åŠ¡åˆ—è¡¨ã€‚")

    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦è·³è¿‡æ•°æ®å‡†å¤‡
    if not SKIP_DATA_PREPARATION:
        logging.info("âš™ï¸ æ¨¡å¼: å®Œæ•´æ•°æ®å‡†å¤‡ (æ£€æŸ¥ã€ä¸‹è½½ã€å†™å…¥)...")
        data_manager.prepare_data_for_universe()
        logging.info("âœ… å®Œæ•´æ•°æ®å‡†å¤‡æµç¨‹ (ETL) å·²å®Œæˆã€‚")
    else:
        logging.info(
            "ğŸŸ¡ ã€ã€è·³è¿‡ã€‘ã€‘: å·²æŒ‰é…ç½® (SKIP_DATA_PREPARATION=True) è·³è¿‡æ•°æ®æ£€æŸ¥ä¸ä¸‹è½½æµç¨‹ã€‚")

    # è·å–åŸºå‡†æ•°æ®ç”¨äºæŠ¥å‘Šå¯¹æ¯”
    logging.info(f"âš™ï¸ æ­£åœ¨è·å–åŸºå‡† '{BENCHMARK}' æ•°æ®ç”¨äºæŠ¥å‘Šå¯¹æ¯”...")
    benchmark_df = data_manager.get_dataframe(BENCHMARK)
    if benchmark_df is None or benchmark_df.empty:
        logging.warning(f"âš ï¸ è­¦å‘Š: æœªèƒ½è·å–åˆ°åŸºå‡† '{BENCHMARK}' çš„æ•°æ®ã€‚")
    else:
        logging.info(f"âœ… æˆåŠŸè·å–åŸºå‡† '{BENCHMARK}' æ•°æ®ã€‚")

    # å®šä¹‰ç”¨äºå› å­è®¡ç®—çš„æœ‰æ•ˆè‚¡ç¥¨æ± ï¼ˆæ’é™¤åŸºå‡†ï¼‰
    active_universe = data_manager.symbols.copy()
    if BENCHMARK in active_universe:
        active_universe.remove(BENCHMARK)
        logging.info(f"  > å·²ä»å› å­è®¡ç®—æ± ä¸­ç§»é™¤åŸºå‡† {BENCHMARK}ã€‚")

    # ==============================================================================
    # ã€ã€ã€ã€ã€ã€ æ–°å¢æ­¥éª¤ 1.5: ç»Ÿä¸€è®¡ç®—æœªæ¥æ”¶ç›Šç‡ ã€‘ã€‘ã€‘ã€‘ã€‘ã€‘
    # è¿™æ˜¯æ¶æ„ä¼˜åŒ–çš„æ ¸å¿ƒï¼šå°†æ”¶ç›Šç‡è®¡ç®—ä¸å› å­è®¡ç®—å®Œå…¨åˆ†ç¦»ã€‚
    # æ— è®ºåç»­è¿è¡Œä½•ç§å› å­ï¼Œæ”¶ç›Šç‡ï¼ˆâ€œç­”æ¡ˆâ€ï¼‰éƒ½é¢„å…ˆåœ¨è¿™é‡Œä¸€æ¬¡æ€§è®¡ç®—å¥½ã€‚
    # ==============================================================================
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 1.5: é¢„è®¡ç®—æ‰€æœ‰æœªæ¥æ”¶ç›Šç‡ ---\n{'='*60}")
    future_returns_df = data_manager.calculate_universe_forward_returns(
        universe=active_universe,
        forward_return_periods=FORWARD_RETURN_PERIODS)
    if future_returns_df is None or future_returns_df.empty:
        logging.critical("â›” è‡´å‘½é”™è¯¯: æœªèƒ½è®¡ç®—å‡ºæœªæ¥æ”¶ç›Šç‡ï¼Œåç»­åˆ†ææ— æ³•è¿›è¡Œã€‚ç¨‹åºç»ˆæ­¢ã€‚")
        sys.exit()

    # å°† date è®¾ä¸ºç´¢å¼•ä»¥ä¼˜åŒ–åç»­åˆå¹¶æ€§èƒ½
    future_returns_df.set_index('date', inplace=True)
    logging.info(f"âœ… æœªæ¥æ”¶ç›Šç‡é¢„è®¡ç®—å®Œæˆã€‚")

    # =====================
    # 2. è®¡ç®—æ‰€æœ‰å› å­çš„åŸå§‹å€¼
    # =====================
    all_factors_dfs = {}
    all_data_df = None

    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 2: è®¡ç®—æ‰€æœ‰æŒ‡å®šå› å­çš„åŸå§‹å€¼ ---\n{'='*60}")

    # --- æ­¥éª¤ 2a: è®¡ç®—åŸºç¡€å› å­ (Type 1) ---
    if not FACTORS_TO_ANALYZE:
        logging.info("â„¹ï¸ (è·³è¿‡: æœªåœ¨ 1b ä¸­é…ç½®åŸºç¡€å› å­)")
    else:
        for factor_name, factor_params in FACTORS_TO_ANALYZE:
            logging.info(
                f"âš™ï¸ æ­£åœ¨å¯åŠ¨ (Type 1) è®¡ç®—å™¨: {factor_name} (å‚æ•°: {factor_params})..."
            )
            # ã€ã€ã€ä¿®æ”¹ã€‘ã€‘ã€‘: FactorCalculator ä¸å†éœ€è¦ forward_return_periods å‚æ•°
            calculator = FactorCalculator(
                provider_configs=data_manager.provider_configs,
                db_path=BACKTEST_DB_PATH,
                universe=active_universe,
                start_date=START_DATE,
                end_date=END_DATE,
                factor_name=factor_name,
                factor_params=factor_params,
                num_threads=FACTOR_CALC_PROCESSES)
            # ã€ã€ã€ä¿®æ”¹ã€‘ã€‘ã€‘: è°ƒç”¨æ–°çš„ã€æ›´çº¯ç²¹çš„ calculate_factor æ–¹æ³•
            factor_data_df = calculator.calculate_factor()

            if not factor_data_df.empty:
                # ã€ã€ã€ä¿®æ”¹ã€‘ã€‘ã€‘: ä¸å†æœ‰ä»è¿™é‡Œè·å– future_returns_df çš„é€»è¾‘
                factor_series = factor_data_df.set_index(
                    'asset', append=True)['factor_value']
                factor_series.name = factor_name
                all_factors_dfs[factor_name] = factor_series.sort_index()
                logging.info(f"âœ… æˆåŠŸè®¡ç®—å¹¶å­˜å‚¨ (Type 1) å› å­: {factor_name}")

    # --- æ­¥éª¤ 2b: è®¡ç®—å¤åˆå› å­ (Type 2) ---
    if not COMPLEX_FACTORS_TO_RUN:
        logging.info("â„¹ï¸ (è·³è¿‡: æœªåœ¨ 1c ä¸­é…ç½®å¤åˆå› å­)")
    else:
        logging.info("âš™ï¸ æ­£åœ¨å‡†å¤‡ (Type 2) å¤åˆå› å­è®¡ç®—æ‰€éœ€çš„å…¨é‡æ•°æ®...")
        all_data_df = data_manager.get_all_data_for_universe(active_universe)

        if all_data_df is None:
            logging.error("âŒ é”™è¯¯: æ— æ³•åŠ è½½å¤åˆå› å­æ‰€éœ€çš„åŸºç¡€æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
        else:
            if LOAD_INDUSTRY_DATA:
                logging.info("  > æ­£åœ¨åŠ è½½å¹¶åˆå¹¶è¡Œä¸šæ•°æ®...")
                industry_df = data_manager.get_industry_mapping()
                if industry_df is not None:
                    # ã€ã€ã€ä¿®å¤ã€‘ã€‘ã€‘: é‡‡ç”¨æ­£ç¡®çš„åˆå¹¶ä¸ç´¢å¼•é‡å»ºæµç¨‹ï¼Œç¡®ä¿ all_data_df ç»“æ„æ­£ç¡®
                    all_data_df = all_data_df.reset_index().merge(
                        industry_df, on='asset',
                        how='left').set_index(['date', 'asset']).sort_index()
                    all_data_df['industry'] = all_data_df.groupby(
                        level='asset')['industry'].ffill().bfill()
                    logging.info("  > âœ… è¡Œä¸šæ•°æ®åˆå¹¶å¹¶é‡å»ºç´¢å¼•å®Œæˆã€‚")
                else:
                    logging.warning("  > âš ï¸ è­¦å‘Š: æœªèƒ½ä» 'stock_kind' åŠ è½½è¡Œä¸šæ•°æ®ã€‚")

            for factor_name in COMPLEX_FACTORS_TO_RUN:
                if factor_name in COMPLEX_FACTOR_REGISTRY:
                    logging.info(f"âš™ï¸ æ­£åœ¨è®¡ç®— (Type 2) å¤åˆå› å­: {factor_name}...")
                    factor_func = COMPLEX_FACTOR_REGISTRY[factor_name]
                    # ã€ã€ã€ä¿®å¤ã€‘ã€‘ã€‘: å¤åˆå› å­å‡½æ•°æ˜¯ç‹¬ç«‹çš„ï¼Œåªéœ€ all_data_df
                    factor_series = factor_func(all_data_df)
                    factor_series.name = factor_name
                    all_factors_dfs[factor_name] = factor_series.sort_index()
                    logging.info(f"âœ… æˆåŠŸè®¡ç®—å¹¶å­˜å‚¨ (Type 2) å› å­: {factor_name}")

    # ã€ã€ã€ç§»é™¤ã€‘ã€‘ã€‘: ä¹‹å‰ä¸ºäº†ä¿®å¤bugè€Œå¢åŠ çš„â€œä¿é™©â€è¡¥ç®—é€»è¾‘å·²ä¸å†éœ€è¦ã€‚

    # =====================
    # 3. å› å­åˆå¹¶ä¸åˆ†æ
    # =====================
    final_factor_data_df = pd.DataFrame()
    final_factor_name = ""

    FACTOR_NAMES = list(all_factors_dfs.keys())
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 3: å› å­åˆå¹¶ä¸åˆ†æ ---\n{'='*60}")
    logging.info(f"â„¹ï¸ å³å°†åˆå¹¶çš„ã€æ‰€æœ‰ã€‘å› å­: {FACTOR_NAMES}")

    if not FACTOR_NAMES:
        logging.warning("âš ï¸ æ²¡æœ‰ä»»ä½•å› å­è¢«è®¡ç®—ï¼Œåˆ†ææµç¨‹ç»ˆæ­¢ã€‚")
    elif len(FACTOR_NAMES) == 1:
        logging.info("â„¹ï¸ åªæœ‰ä¸€ä¸ªå› å­ï¼Œç›´æ¥è¿›å…¥æŠ¥å‘Šç”Ÿæˆé˜¶æ®µã€‚")
        final_factor_name = FACTOR_NAMES[0]
        final_factor_series = all_factors_dfs[final_factor_name]
        combined_factors_df = final_factor_series.to_frame()
    else:
        # --- å¤šå› å­åˆæˆè·¯å¾„ ---
        logging.info("âš™ï¸ æ­¥éª¤ 3a: åˆå¹¶æ‰€æœ‰å› å­æ•°æ®...")
        combined_factors_df = pd.concat(all_factors_dfs.values(),
                                        axis=1,
                                        keys=all_factors_dfs.keys())
        if isinstance(combined_factors_df.columns, pd.MultiIndex):
            combined_factors_df.columns = combined_factors_df.columns.droplevel(
                1)
        combined_factors_df = combined_factors_df[FACTOR_NAMES]
        logging.info(f"  > âœ… æˆåŠŸåˆå¹¶ {len(FACTOR_NAMES)} ä¸ªå› å­ã€‚")

        # æ ¸å¿ƒé€»è¾‘åˆ†æ”¯ï¼šé™æ€ vs æ»šåŠ¨
        if not STRATEGY_CONFIG.is_rolling():
            # åˆ†æ”¯A: é™æ€æƒé‡é€»è¾‘
            logging.info(
                f"â„¹ï¸ æ¨¡å¼: é™æ€åˆæˆ (ç­–ç•¥: {STRATEGY_CONFIG.combiner_class.__name__})")
            combiner = STRATEGY_CONFIG.combiner_class(
                **STRATEGY_CONFIG.combiner_kwargs)
            logging.info(
                f"âš™ï¸ æ­¥éª¤ 3b: æ‰§è¡Œæˆªé¢æ ‡å‡†åŒ– ({STANDARDIZER.__class__.__name__})...")
            standardized_factors_df = combined_factors_df.groupby(
                level='date').apply(lambda x: STANDARDIZER.standardize(x))
            logging.info("âš™ï¸ æ­¥éª¤ 3c: æ‰§è¡Œå› å­åˆæˆ...")
            composite_factor_series = standardized_factors_df.groupby(
                level='date').apply(lambda x: combiner.combine(x))
            composite_factor_series.name = 'factor_value'
            final_factor_name = f"CompositeFactor_{STRATEGY_NAME}"
        else:
            # åˆ†æ”¯B: åŠ¨æ€æ»šåŠ¨æƒé‡é€»è¾‘
            logging.info(f"â„¹ï¸ æ¨¡å¼: åŠ¨æ€æ»šåŠ¨ (æ¯æ—¥æƒé‡è®¡ç®—æ¨¡å¼)")
            roller = STRATEGY_CONFIG.create_rolling_calculator(
                forward_return_periods=FORWARD_RETURN_PERIODS,
                factor_names=FACTOR_NAMES)
            logging.info("âš™ï¸ æ­¥éª¤ 3c: å‡†å¤‡æ»šåŠ¨æ•°æ® (åˆå¹¶å› å­ä¸æœªæ¥æ”¶ç›Š)...")
            all_data_merged = pd.merge(
                combined_factors_df.reset_index(),
                future_returns_df.reset_index(
                ),  # future_returns_df çš„ç´¢å¼•æ˜¯ date, reset åå˜ä¸ºåˆ—
                on=['date', 'asset'],
                how='inner')
            all_data_merged.set_index(['date', 'asset'], inplace=True)
            all_data_merged.sort_index(inplace=True)
            logging.info(f"  > âœ… æ»šåŠ¨æ•°æ®å‡†å¤‡å®Œæ¯•ï¼Œå…± {len(all_data_merged)} æ¡åˆå¹¶è®°å½•ã€‚")
            composite_factor_series = roller.calculate_composite_factor(
                all_data_merged)
            composite_factor_series.name = 'factor_value'
            final_factor_name = f"CompositeFactor_{STRATEGY_NAME}_Rolling"

        combined_factors_df = composite_factor_series.to_frame()

    # --- åˆå¹¶æœªæ¥æ”¶ç›Šä»¥ç”ŸæˆæŠ¥å‘Š ---
    if not combined_factors_df.empty:
        final_factor_data_df = pd.merge(combined_factors_df.reset_index(),
                                        future_returns_df.reset_index(),
                                        on=['date', 'asset'],
                                        how='inner')
        final_factor_data_df.rename(
            columns={'factor_value': final_factor_name}, inplace=True)
        final_factor_data_df.set_index('date', inplace=True)

    # =====================
    # 4. ç”Ÿæˆæœ€ç»ˆçš„å› å­åˆ†ææŠ¥å‘Š
    # =====================
    if not final_factor_data_df.empty:
        logging.info(
            f"\n{'='*60}\n--- æ­¥éª¤ 4: ä¸ºæœ€ç»ˆå› å­ '{final_factor_name}' ç”Ÿæˆåˆ†ææŠ¥å‘Š ---\n{'='*60}"
        )
        final_report_df = final_factor_data_df.rename(
            columns={final_factor_name: 'factor_value'})
        final_report_df.dropna(subset=['factor_value'], inplace=True)

        if final_report_df.empty:
            logging.warning(f"  > âš ï¸ è­¦å‘Š: æœ€ç»ˆå› å­ '{final_factor_name}' æ•°æ®åœ¨æ¸…ç†åä¸ºç©ºã€‚")
        else:
            logging.info(f"  > âœ… æœ€ç»ˆå› å­æ•°æ®å‡†å¤‡å®Œæˆï¼Œå…± {len(final_report_df)} æ¡æœ‰æ•ˆè®°å½•ã€‚")
            report_generator = FactorReport(
                factor_name=final_factor_name,
                factor_data=final_report_df,
                forward_return_periods=FORWARD_RETURN_PERIODS,
                benchmark_data=benchmark_df)
            output_filename = os.path.join(OUTPUT_DIR,
                                           f"report_{final_factor_name}.html")
            logging.info(f"âš™ï¸ æ­£åœ¨ç”Ÿæˆ HTML æŠ¥å‘Šè‡³: {output_filename}")
            report_generator.generate_html_report(output_filename)

    logging.info(f"\n{'='*60}")
    logging.info("ğŸ æ‰€æœ‰å› å­åˆ†ææµç¨‹æ‰§è¡Œå®Œæ¯• ğŸ")
    logging.info(f"{'='*60}")
