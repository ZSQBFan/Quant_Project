# main_analyzer.py

import os
import logging
import pandas as pd
from tqdm import tqdm
import sys

# ==============================================================================
# 1. ç­–ç•¥åˆ†æâ€œæ§åˆ¶é¢æ¿â€ (Strategy Analysis "Control Panel")
# ==============================================================================

# --- 1a. æ ¸å¿ƒç­–ç•¥é€‰æ‹© (Core Strategy Selection) ---
from strategy_configs import STRATEGY_REGISTRY

# ã€ã€è¯·åœ¨è¿™é‡Œé€‰æ‹©æ‚¨çš„ç­–ç•¥åç§° (ä» strategy_configs.py å¤åˆ¶)ã€‘ã€‘
# STRATEGY_NAME = "RollingICIR_Daily"
# STRATEGY_NAME = "RollingRegression_Daily"
# STRATEGY_NAME = "FixedWeights"
# STRATEGY_NAME = "EqualWeights"
# STRATEGY_NAME = "DynamicSignificance"
STRATEGY_NAME = "AI_Periodic_Retrain"

if STRATEGY_NAME not in STRATEGY_REGISTRY:
    raise ValueError(f"ç­–ç•¥ '{STRATEGY_NAME}' æœªåœ¨ strategy_configs.py ä¸­æ³¨å†Œã€‚")
STRATEGY_CONFIG = STRATEGY_REGISTRY[STRATEGY_NAME]

# --- ã€ã€ã€æ–°ã€‘ã€‘ã€‘ 1b. å› å­é€‰æ‹© (Factors to Analyze) ---
#
#   ç°åœ¨æ‚¨åªéœ€è¦åˆ—å‡ºå› å­åç§°ã€‚
#   å…·ä½“çš„å‚æ•° (params) å’Œæ•°æ®ä¾èµ– (required_columns) å·²åœ¨ factor_configs.py ä¸­ç»Ÿä¸€å®šä¹‰ã€‚
#
from factor_configs import FACTOR_REGISTRY

FACTORS_TO_ANALYZE = [
    # 'Momentum',
    # 'Reversal20D',
    # 'RSI',
    # 'BollingerBands',
]

# --- 1c. å¤åˆå› å­é€‰æ‹© (Complex Factors) ---
from factor_analysis.factors_complex import COMPLEX_FACTOR_REGISTRY

COMPLEX_FACTORS_TO_RUN = [
    "IndNeu_Momentum",
    "IndNeu_Reversal20D",
    "IndNeu_VolumeCV",
]

# --- 1d. æˆªé¢æ•°æ®é…ç½® (Cross-Sectional Data) ---
#   ã€å…¨å±€å¼€å…³ã€‘: æ˜¯å¦åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½å¼ºåˆ¶åŠ è½½è¡Œä¸šæ•°æ®ï¼Ÿ
#   (å³ä½¿å½“å‰è®¡ç®—çš„å› å­ä¸éœ€è¦è¡Œä¸šæ•°æ®ï¼Œå¦‚æœæ‚¨æƒ³åœ¨ç”Ÿæˆçš„æŠ¥å‘Šä¸­æŒ‰è¡Œä¸šåˆ†ç»„æŸ¥çœ‹ï¼Œä¹Ÿéœ€è¦å¼€å¯æ­¤é¡¹)
LOAD_INDUSTRY_DATA = False

# --- 1e. æ ‡å‡†åŒ–å™¨ (Standardizer) ---
from strategies.standardizers import (CrossSectionalZScoreStandardizer,
                                      NoStandardizer,
                                      CrossSectionalQuantileStandardizer)

STANDARDIZER_CLASS = CrossSectionalZScoreStandardizer

# ==============================================================================
# 2. åŸºç¡€å›æµ‹ä¸è·¯å¾„é…ç½® (Basic Backtest & Path Settings)
# ==============================================================================

#   ã€ã€ã€é‡è¦ã€‘ã€‘ã€‘æ•°æ®ä¸‹è½½ä¸å†™å…¥å¼€å…³ï¼š
#   True: è·³è¿‡ä¸‹è½½ï¼Œç›´æ¥ä½¿ç”¨æ•°æ®åº“ (è°ƒè¯•å› å­é€»è¾‘æ—¶ç”¨)
#   False: æ£€æŸ¥å¹¶ä¸‹è½½ç¼ºå¤±æ•°æ® (æ—¥å¸¸æ›´æ–°æ•°æ®æ—¶ç”¨)
SKIP_DATA_PREPARATION = True

# --- 2a. å›æµ‹æ—¶é—´ä¸æ”¶ç›Šå‘¨æœŸ ---
START_DATE = '2018-01-01'
END_DATE = '2020-12-31'
FORWARD_RETURN_PERIODS = [1, 5, 10, 20, 30, 90]

# --- 2b. åŸºå‡†ä¸è‚¡ç¥¨æ±  ---
BENCHMARK = '600519'  # èŒ…å°
from universe_config import UNIVERSE

# å› å­è®¡ç®—è¿›ç¨‹æ•°
FACTOR_CALC_PROCESSES = 8

# --- 2c. è·¯å¾„é…ç½® ---
LOG_DIR = "logs"
OUTPUT_DIR = "factor_reports"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
BACKTEST_DB_PATH = './database/quant_data.db'

# --- 2d. æ•°æ®æºé…ç½® ---
from data.data_providers import SQLiteDataProvider

DATA_PROVIDERS_CONFIG = [
    (
        SQLiteDataProvider,
        {
            'db_path': './database/JY_database/sqlite/JY_database.sqlite',
            'table_name': 'JY_t_price_daily'  # æˆ–è€…æ˜¯æ‚¨çš„æ•°æ®æºè¡¨å
        }),
]

# ==============================================================================
#
#                     --- æ ¸å¿ƒç¨‹åºå¼€å§‹ (Core Logic Starts) ---
#
# ==============================================================================

from data.data_manager import DataProviderManager
from factor_analysis.factor_calculator import FactorCalculator
from factor_analysis.factor_report import FactorReport
from logger.logger_config import setup_logging

if __name__ == '__main__':

    # =====================
    # 0. åˆå§‹åŒ–ä¸é…ç½®æ ¡éªŒ
    # =====================
    setup_logging(log_dir=LOG_DIR, log_prefix='factor_analysis')
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 0: åˆå§‹åŒ–ä¸é…ç½®æ ¡éªŒ ---\n{'='*60}")
    logging.info("ğŸ å› å­åˆ†æç¨‹åºå¯åŠ¨...")

    STANDARDIZER = STANDARDIZER_CLASS()
    logging.info(f"âœ… æ ‡å‡†åŒ–å™¨å·²åŠ è½½: {STANDARDIZER.__class__.__name__}")
    logging.info(f"âš™ï¸ æ­£åœ¨åŠ è½½ç­–ç•¥: {STRATEGY_NAME}")

    # =====================
    # 1. åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    # =====================
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 1: å‡†å¤‡æ•°æ® ---\n{'='*60}")
    logging.info("âš™ï¸ æ­£åœ¨åˆå§‹åŒ– DataProviderManager...")
    data_manager = DataProviderManager(provider_configs=DATA_PROVIDERS_CONFIG,
                                       symbols=UNIVERSE,
                                       start_date=START_DATE,
                                       end_date=END_DATE,
                                       db_path=BACKTEST_DB_PATH,
                                       num_checker_threads=16,
                                       num_downloader_threads=16,
                                       batch_size=200)

    if BENCHMARK not in data_manager.symbols:
        data_manager.symbols.append(BENCHMARK)

    if not SKIP_DATA_PREPARATION:
        logging.info("âš™ï¸ æ¨¡å¼: å®Œæ•´æ•°æ®å‡†å¤‡ (æ£€æŸ¥ã€ä¸‹è½½ã€å†™å…¥)...")
        data_manager.prepare_data_for_universe()
    else:
        logging.info("ğŸŸ¡ ã€ã€è·³è¿‡ã€‘ã€‘: å·²æŒ‰é…ç½®è·³è¿‡æ•°æ®ä¸‹è½½æµç¨‹ã€‚")

    # è·å–åŸºå‡†æ•°æ®
    logging.info(f"âš™ï¸ è·å–åŸºå‡† '{BENCHMARK}' æ•°æ®...")
    benchmark_df = data_manager.get_dataframe(BENCHMARK, columns=['close'])

    active_universe = data_manager.symbols.copy()
    if BENCHMARK in active_universe:
        active_universe.remove(BENCHMARK)

    # =====================
    # 1.5 ç»Ÿä¸€è®¡ç®—æœªæ¥æ”¶ç›Šç‡
    # =====================
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 1.5: é¢„è®¡ç®—æœªæ¥æ”¶ç›Šç‡ ---\n{'='*60}")
    future_returns_df = data_manager.calculate_universe_forward_returns(
        universe=active_universe,
        forward_return_periods=FORWARD_RETURN_PERIODS)

    if future_returns_df is None or future_returns_df.empty:
        logging.critical("â›” è‡´å‘½é”™è¯¯: æœªèƒ½è®¡ç®—å‡ºæœªæ¥æ”¶ç›Šç‡ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        sys.exit()

    future_returns_df.set_index('date', inplace=True)

    # ==============================================================================
    # ã€ã€ã€æ–°å¢æ­¥éª¤ 1.7: é¢„è®¡ç®—æ‰€éœ€æ•°æ®åˆ— (æŒ‰éœ€åŠ è½½æ ¸å¿ƒ)ã€‘ã€‘ã€‘
    # ==============================================================================
    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 1.7: é¢„è®¡ç®—æ‰€æœ‰å› å­æ‰€éœ€çš„æ•°æ®åˆ— ---\n{'='*60}")

    all_required_columns = set()
    all_factors_to_run = FACTORS_TO_ANALYZE + COMPLEX_FACTORS_TO_RUN

    for factor_name in all_factors_to_run:
        # å…¼å®¹å¤„ç†ï¼šå¦‚æœç”¨æˆ·åœ¨ FACTORS_TO_ANALYZE ä¸­å†™äº†å…ƒç»„ ('Name', params)ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
        if isinstance(factor_name, tuple):
            factor_name = factor_name[0]

        if factor_name in FACTOR_REGISTRY:
            required = FACTOR_REGISTRY[factor_name].get('required_columns', [])
            all_required_columns.update(required)
        else:
            logging.warning(
                f"âš ï¸ è­¦å‘Š: å› å­ '{factor_name}' æœªåœ¨ FACTOR_REGISTRY ä¸­æ³¨å†Œï¼Œå°†æ— æ³•æŒ‰éœ€åŠ è½½ã€‚")

    # å¤„ç†å…¨å±€è¡Œä¸šæ•°æ®å¼€å…³
    if LOAD_INDUSTRY_DATA:
        all_required_columns.add('industry')

    # æ’åºä»…ä¸ºäº†æ—¥å¿—ç¾è§‚
    sorted_cols = sorted(list(all_required_columns))
    logging.info(f"âœ… æœ¬æ¬¡è¿è¡Œä¼˜åŒ–åçš„æ•°æ®åˆ—éœ€æ±‚: {sorted_cols}")

    # =====================
    # 2. è®¡ç®—å› å­åŸå§‹å€¼
    # =====================
    all_factors_dfs = {}
    all_data_df = None

    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 2: è®¡ç®—æ‰€æœ‰æŒ‡å®šå› å­çš„åŸå§‹å€¼ ---\n{'='*60}")

    # --- æ­¥éª¤ 2a: è®¡ç®—åŸºç¡€å› å­ (Type 1) ---
    if not FACTORS_TO_ANALYZE:
        logging.info("â„¹ï¸ (è·³è¿‡: æœªé…ç½®åŸºç¡€å› å­)")
    else:
        for factor_item in FACTORS_TO_ANALYZE:
            # å…¼å®¹æ—§æ ¼å¼ (name, params) æˆ–æ–°æ ¼å¼ name
            if isinstance(factor_item, tuple):
                factor_name = factor_item[0]
                # å¦‚æœç”¨æˆ·åœ¨ main ä¸­æŒ‡å®šäº†å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ï¼›å¦åˆ™ç”¨ Registry çš„
                factor_params = factor_item[1] if len(factor_item) > 1 else {}
            else:
                factor_name = factor_item
                factor_params = {}  # ç¨åä¼šä» Registry åˆå¹¶

            # ä» Registry è·å–æ ‡å‡†é…ç½®
            registry_config = FACTOR_REGISTRY.get(factor_name, {})
            registry_params = registry_config.get('params', {})
            required_cols = registry_config.get('required_columns', [])

            # åˆå¹¶å‚æ•° (main é…ç½®è¦†ç›– registry é…ç½®)
            final_params = {**registry_params, **factor_params}

            logging.info(
                f"âš™ï¸ å¯åŠ¨ (Type 1) è®¡ç®—å™¨: {factor_name} (Cols: {required_cols})..."
            )

            calculator = FactorCalculator(
                provider_configs=data_manager.provider_configs,
                db_path=BACKTEST_DB_PATH,
                universe=active_universe,
                start_date=START_DATE,
                end_date=END_DATE,
                factor_name=factor_name,
                factor_params=final_params,
                num_threads=FACTOR_CALC_PROCESSES,
                required_columns=required_cols  # ã€ã€ã€æ ¸å¿ƒï¼šæŒ‰éœ€åŠ è½½ã€‘ã€‘ã€‘
            )

            factor_data_df = calculator.calculate_factor()

            if not factor_data_df.empty:
                factor_series = factor_data_df.set_index(
                    'asset', append=True)['factor_value']
                factor_series.name = factor_name
                all_factors_dfs[factor_name] = factor_series.sort_index()
                logging.info(f"âœ… æˆåŠŸè®¡ç®—: {factor_name}")

    # --- æ­¥éª¤ 2b: è®¡ç®—å¤åˆå› å­ (Type 2) ---
    if not COMPLEX_FACTORS_TO_RUN:
        logging.info("â„¹ï¸ (è·³è¿‡: æœªé…ç½®å¤åˆå› å­)")
    else:
        logging.info("âš™ï¸ æ­£åœ¨å‡†å¤‡ (Type 2) å¤åˆå› å­è®¡ç®—æ‰€éœ€çš„å…¨é‡æ•°æ®...")
        # ã€ã€ã€æ ¸å¿ƒï¼šåªåŠ è½½æ‰€æœ‰å› å­éœ€è¦çš„åˆ—å¹¶é›†ã€‘ã€‘ã€‘
        all_data_df = data_manager.get_all_data_for_universe(
            active_universe, required_columns=list(all_required_columns))

        if all_data_df is None:
            logging.error("âŒ æ— æ³•åŠ è½½å¤åˆå› å­æ‰€éœ€çš„åŸºç¡€æ•°æ®ã€‚")
        else:
            # è¿™é‡Œçš„è¡Œä¸šæ•°æ®å·²ç»åœ¨ get_all_data_for_universe ä¸­æ ¹æ® 'industry' åˆ—è‡ªåŠ¨åˆå¹¶äº†
            # æ‰€ä»¥ä¸éœ€è¦åƒä»¥å‰é‚£æ ·æ‰‹åŠ¨ merge get_industry_mapping

            for factor_name in COMPLEX_FACTORS_TO_RUN:
                if factor_name in COMPLEX_FACTOR_REGISTRY:
                    logging.info(f"âš™ï¸ è®¡ç®— (Type 2) å¤åˆå› å­: {factor_name}...")
                    factor_func = COMPLEX_FACTOR_REGISTRY[factor_name]
                    factor_series = factor_func(all_data_df)
                    if factor_series is not None:
                        factor_series.name = factor_name
                        all_factors_dfs[
                            factor_name] = factor_series.sort_index()
                        logging.info(f"âœ… æˆåŠŸè®¡ç®—: {factor_name}")

    # =====================
    # 3. å› å­åˆå¹¶ä¸åˆ†æ
    # =====================
    final_factor_data_df = pd.DataFrame()
    final_factor_name = ""
    FACTOR_NAMES = list(all_factors_dfs.keys())

    logging.info(f"\n{'='*60}\n--- æ­¥éª¤ 3: å› å­åˆå¹¶ä¸åˆ†æ ---\n{'='*60}")
    logging.info(f"â„¹ï¸ å¾…åˆå¹¶å› å­: {FACTOR_NAMES}")

    if not FACTOR_NAMES:
        logging.warning("âš ï¸ æ²¡æœ‰è®¡ç®—å‡ºä»»ä½•å› å­ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
    elif len(FACTOR_NAMES) == 1:
        logging.info("â„¹ï¸ å•å› å­æ¨¡å¼ã€‚")
        final_factor_name = FACTOR_NAMES[0]
        combined_factors_df = all_factors_dfs[final_factor_name].to_frame()
    else:
        logging.info("âš™ï¸ æ­¥éª¤ 3a: åˆå¹¶å› å­æ•°æ®...")
        combined_factors_df = pd.concat(all_factors_dfs.values(),
                                        axis=1,
                                        keys=all_factors_dfs.keys())
        if isinstance(combined_factors_df.columns, pd.MultiIndex):
            combined_factors_df.columns = combined_factors_df.columns.droplevel(
                1)

        # æ ¸å¿ƒç­–ç•¥é€»è¾‘
        if not STRATEGY_CONFIG.is_rolling():
            # A. é™æ€ç­–ç•¥
            logging.info(
                f"â„¹ï¸ æ¨¡å¼: é™æ€åˆæˆ (ç­–ç•¥: {STRATEGY_CONFIG.combiner_class.__name__})")
            combiner = STRATEGY_CONFIG.combiner_class(
                **STRATEGY_CONFIG.combiner_kwargs)

            logging.info(
                f"âš™ï¸ æ­¥éª¤ 3b: æˆªé¢æ ‡å‡†åŒ– ({STANDARDIZER.__class__.__name__})...")
            standardized_factors_df = combined_factors_df.groupby(
                level='date').apply(lambda x: STANDARDIZER.standardize(x))

            logging.info("âš™ï¸ æ­¥éª¤ 3c: å› å­åˆæˆ...")
            composite_factor_series = standardized_factors_df.groupby(
                level='date').apply(lambda x: combiner.combine(x))
            composite_factor_series.name = 'factor_value'
            final_factor_name = f"Composite_{STRATEGY_NAME}"
        else:
            # B. åŠ¨æ€æ»šåŠ¨ç­–ç•¥
            logging.info(f"â„¹ï¸ æ¨¡å¼: åŠ¨æ€æ»šåŠ¨ (æ¯æ—¥æƒé‡è®¡ç®—)")
            roller = STRATEGY_CONFIG.create_rolling_calculator(
                forward_return_periods=FORWARD_RETURN_PERIODS,
                factor_names=FACTOR_NAMES)

            logging.info("âš™ï¸ æ­¥éª¤ 3c: å‡†å¤‡æ»šåŠ¨æ•°æ®...")
            # åˆå¹¶å› å­å€¼å’Œæœªæ¥æ”¶ç›Š (ç”¨äºè®¡ç®— IC/IR ç­‰)
            all_data_merged = pd.merge(combined_factors_df.reset_index(),
                                       future_returns_df.reset_index(),
                                       on=['date', 'asset'],
                                       how='inner').set_index(
                                           ['date', 'asset']).sort_index()

            composite_factor_series = roller.calculate_composite_factor(
                all_data_merged)
            composite_factor_series.name = 'factor_value'
            final_factor_name = f"Composite_{STRATEGY_NAME}_Rolling"

        combined_factors_df = composite_factor_series.to_frame()

    # =====================
    # 4. ç”ŸæˆæŠ¥å‘Š
    # =====================
    if not combined_factors_df.empty:
        # åˆå¹¶æ”¶ç›Šç‡ç”¨äºæœ€ç»ˆæŠ¥å‘Š
        final_factor_data_df = pd.merge(combined_factors_df.reset_index(),
                                        future_returns_df.reset_index(),
                                        on=['date', 'asset'],
                                        how='inner')
        final_factor_data_df.rename(
            columns={'factor_value': final_factor_name}, inplace=True)
        final_factor_data_df.set_index('date', inplace=True)

        logging.info(
            f"\n{'='*60}\n--- æ­¥éª¤ 4: ç”ŸæˆæŠ¥å‘Š ({final_factor_name}) ---\n{'='*60}")

        final_report_df = final_factor_data_df.rename(
            columns={final_factor_name: 'factor_value'})
        final_report_df.dropna(subset=['factor_value'], inplace=True)

        if not final_report_df.empty:
            report_generator = FactorReport(
                factor_name=final_factor_name,
                factor_data=final_report_df,
                forward_return_periods=FORWARD_RETURN_PERIODS,
                benchmark_data=benchmark_df)

            output_filename = os.path.join(OUTPUT_DIR,
                                           f"report_{final_factor_name}.html")
            logging.info(f"âš™ï¸ ç”Ÿæˆ HTML æŠ¥å‘Š: {output_filename}")
            report_generator.generate_html_report(output_filename)
        else:
            logging.warning("âš ï¸ æœ€ç»ˆå› å­æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Šã€‚")

    logging.info(f"\n{'='*60}\nğŸ åˆ†ææµç¨‹æ‰§è¡Œå®Œæ¯• ğŸ\n{'='*60}")
